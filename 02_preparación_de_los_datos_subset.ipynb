{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d330b941",
   "metadata": {},
   "source": [
    "# Preparación para el TF MDS\n",
    "\n",
    "## Preparación de los datos - enfoque en subconjunto del dataset\n",
    "\n",
    "Repo para trabajo de preparación\n",
    "\n",
    "Dataset: https://www.yelp.com/dataset/documentation/main\n",
    "\n",
    "Extraer fotos del RAR en /dataset/photos.\n",
    "\n",
    "Extraer archivo photos.json en /dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cffd6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa0c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar listado de fotos con dimensiones > 224 x 224\n",
    "photo_data = pickle.load(open('checkpoints/df5.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee758302",
   "metadata": {},
   "source": [
    "Vamos crear un sub-dataset con hasta 20.000 fotos de cada etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acdc43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET_SIZE = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97f9e70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>label</th>\n",
       "      <th>x_dim</th>\n",
       "      <th>y_dim</th>\n",
       "      <th>z_channels</th>\n",
       "      <th>pixels</th>\n",
       "      <th>drink</th>\n",
       "      <th>food</th>\n",
       "      <th>inside</th>\n",
       "      <th>menu</th>\n",
       "      <th>outside</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--0h6FMC0V8aMtKQylojEg</td>\n",
       "      <td>inside</td>\n",
       "      <td>400.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--3JQ4MlO-jHT9xbo7liug</td>\n",
       "      <td>food</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 photo_id   label  x_dim  y_dim  z_channels    pixels  drink  \\\n",
       "0  --0h6FMC0V8aMtKQylojEg  inside  400.0  300.0         3.0  120000.0    0.0   \n",
       "1  --3JQ4MlO-jHT9xbo7liug    food  400.0  400.0         3.0  160000.0    0.0   \n",
       "\n",
       "   food  inside  menu  outside  \n",
       "0   0.0     1.0   0.0      0.0  \n",
       "1   1.0     0.0   0.0      0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d64b176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food       106262\n",
       "inside      55214\n",
       "outside     18189\n",
       "drink       15412\n",
       "menu         1583\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_photos = photo_data.label.value_counts()\n",
    "total_photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d590a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = pd.DataFrame([], columns=['photo_id',\n",
    "                                        'label',\n",
    "                                        'x_dim', \n",
    "                                        'y_dim', \n",
    "                                        'z_channels', \n",
    "                                        'pixels', \n",
    "                                        'drink',\n",
    "                                        'food',\n",
    "                                        'inside',\n",
    "                                        'menu',\n",
    "                                        'outside'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aaaafc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in total_photos.index:\n",
    "    if total_photos[label] > SUBSET_SIZE: # take sample of 20.000 photos\n",
    "        df_subset = pd.concat([df_subset,\n",
    "                               photo_data.loc[photo_data.label == label].sample(n=SUBSET_SIZE)])\n",
    "    else: # keep all photos\n",
    "        df_subset = pd.concat([df_subset,\n",
    "                               photo_data.loc[photo_data.label == label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57e3754b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75184"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4712d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food       20000\n",
       "inside     20000\n",
       "outside    18189\n",
       "drink      15412\n",
       "menu        1583\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e079c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_subset, open(\"checkpoints/df_subset.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da26f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "df_subset = pickle.load(open(\"checkpoints/df_subset.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4143f6c",
   "metadata": {},
   "source": [
    "## Escalar y recortar las fotos del subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab0cfeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20000 # Para reducir el consumo de memoria en el procesamiento de imagenes\n",
    "PHOTO_SIZE = 224.0 # De cara a usar https://huggingface.co/facebook/deit-tiny-patch16-224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3e95f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06de936b3fd435b96434aa7ef35da1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Photos cropped:   0%|          | 0/75184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "photo_counter = 0\n",
    "\n",
    "for img in tqdm(range(len(df_subset)), desc='Photos cropped', miniters=100):\n",
    "    # load image\n",
    "    im = Image.open('dataset/photos/' + df_subset.iloc[img].photo_id + '.jpg')\n",
    "\n",
    "    # resize smallest dimension to PHOTO_SIZE\n",
    "    if (df_subset.iloc[img].y_dim < df_subset.iloc[img].x_dim): # narrow image\n",
    "        width = int(PHOTO_SIZE)\n",
    "        height = math.floor(PHOTO_SIZE * df_subset.iloc[img].x_dim/df_subset.iloc[img].y_dim)\n",
    "    else: # wide image\n",
    "        width = math.floor(PHOTO_SIZE * df_subset.iloc[img].y_dim/df_subset.iloc[img].x_dim)\n",
    "        height = int(PHOTO_SIZE)\n",
    "    \n",
    "    resized = T.Resize((height, width))(im)\n",
    "    cropped = T.CenterCrop(size=int(PHOTO_SIZE))(resized)\n",
    "\n",
    "    # convert to numpy array\n",
    "    img_np = np.array(cropped)\n",
    "\n",
    "    if photo_counter % BATCH_SIZE == 0: # save images to file to preserve memory\n",
    "        if photo_counter > 0:\n",
    "            pickle.dump(images,\n",
    "                        open('dataset/processed/subset_images_{}.pkl'.format(photo_counter),\n",
    "                             'wb'))\n",
    "            # print('Saved file images_{}.pkl'.format(photo_counter))\n",
    "        images = [img_np]           # reset image list\n",
    "    else:\n",
    "        images += [img_np]          # add image to list\n",
    "    \n",
    "    photo_counter += 1\n",
    "    \n",
    "pickle.dump(images, open('dataset/processed/subset_images_remainder.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "114fd596",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = ['dataset/processed/subset_images_{}.pkl'.format(y*BATCH_SIZE) for y in range(1,len(df_subset) //BATCH_SIZE + 1)] + ['dataset/processed/subset_images_remainder.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f492957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbb0e91822e4807b8f625840e6fcaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Files loaded:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = []\n",
    "for file in tqdm(file_list, desc='Files loaded', miniters=1):\n",
    "    images += pickle.load(open(file,'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3412e1",
   "metadata": {},
   "source": [
    "## La celda siguiente requiere 22,5 GB de memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "217e601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(images, open('dataset/processed/full_subset.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
