{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e8909e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323b360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesadas 200,070 mil fotos de las cuales 106 est치n corruptas\r"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(r'dataset/photos.json', lines=True)\n",
    "df = df.drop(columns = ['business_id', 'caption'])\n",
    "contador = 0\n",
    "discarded = 0\n",
    "for img in df.photo_id.tolist():\n",
    "    if (contador%30 == 0) and (contador > 0):\n",
    "        print('Procesadas {:7,} mil fotos de las cuales {} est치n corruptas'.format(contador, discarded), end='\\r');\n",
    "    contador += 1\n",
    "    try:\n",
    "        img = Image.open('dataset/photos/'+img+'.jpg')\n",
    "        img.verify()\n",
    "    except:\n",
    "        # file is corrupt\n",
    "        df = df.drop(df.loc[df.photo_id == img].index)\n",
    "        discarded += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34b2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe('photo_id', 'label') contiene todas las fotos v치lidas del dataset\n",
    "pickle.dump(df, open('checkpoints/valid.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7832d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "df = pickle.load(open('checkpoints/valid.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e210b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias = df.label.value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23741b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {'train' : {},\n",
    "          'test': {},\n",
    "          'validate': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "580c784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for categoria in categorias:\n",
    "    slice_80 = int(len(df.loc[df.label == categoria]) * 0.8)\n",
    "    slice_10 = int(len(df.loc[df.label == categoria]) * 0.1)\n",
    "    dataset['train'].update({categoria: df.loc[df.label == categoria][0:slice_80]})\n",
    "    dataset['test'].update({categoria: df.loc[df.label == categoria][slice_80:slice_80+slice_10]})\n",
    "    dataset['validate'].update({categoria: df.loc[df.label == categoria][slice_80+slice_10:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd299c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42 # La soluci칩n de Douglas Adams para todo\n",
    "max_photos = 2500\n",
    "\n",
    "subset_max_photos = {\n",
    "    'train': int(max_photos * 0.8),\n",
    "    'test': int(max_photos * 0.1)\n",
    "}\n",
    "\n",
    "subset_max_photos.update({\n",
    "    'validate': max_photos - subset_max_photos['train'] - subset_max_photos['test'] # las que quedan\n",
    "})\n",
    "\n",
    "# hacer que los subsets tengan max_photos imagenes\n",
    "for subset in ['train', 'test', 'validate']:\n",
    "    for categoria in categorias:\n",
    "        if len(dataset[subset][categoria]) == subset_max_photos[subset]: # tenemos el numero correcto\n",
    "            pass            \n",
    "        elif len(dataset[subset][categoria]) > subset_max_photos[subset]: # demasiadas fotos - resample\n",
    "            dataset[subset][categoria] = dataset[subset][categoria].sample(n=subset_max_photos[subset],\n",
    "                                                                           random_state=random_state,\n",
    "                                                                           replace=False, # solo 1x cada foto\n",
    "                                                                           ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "460434de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/yelp removed\n",
      "dataset/yelp created\n",
      "dataset/yelp/train created\n",
      "dataset/yelp/train/food created\n",
      "dataset/yelp/train/inside created\n",
      "dataset/yelp/train/outside created\n",
      "dataset/yelp/train/drink created\n",
      "dataset/yelp/train/menu created\n",
      "dataset/yelp/test created\n",
      "dataset/yelp/test/food created\n",
      "dataset/yelp/test/inside created\n",
      "dataset/yelp/test/outside created\n",
      "dataset/yelp/test/drink created\n",
      "dataset/yelp/test/menu created\n",
      "dataset/yelp/validate created\n",
      "dataset/yelp/validate/food created\n",
      "dataset/yelp/validate/inside created\n",
      "dataset/yelp/validate/outside created\n",
      "dataset/yelp/validate/drink created\n",
      "dataset/yelp/validate/menu created\n"
     ]
    }
   ],
   "source": [
    "dataset_origin_path='dataset/photos'\n",
    "dataset_output_path='dataset/yelp'\n",
    "dataset_json_file='dataset/photos.json'\n",
    "\n",
    "import shutil\n",
    "\n",
    "# crear estructura de carpetas\n",
    "if os.path.isdir(dataset_output_path):\n",
    "    shutil.rmtree(dataset_output_path, ignore_errors=False, onerror=None) # remove tree\n",
    "    print('{} removed'.format(dataset_output_path))\n",
    "    \n",
    "os.mkdir(dataset_output_path)\n",
    "print('{} created'.format(dataset_output_path))\n",
    "    \n",
    "for subset in ['train', 'test', 'validate']:\n",
    "    os.mkdir(dataset_output_path + '/' + subset)\n",
    "    print('{} created'.format(dataset_output_path + '/' + subset))\n",
    "    for categoria in categorias:\n",
    "        os.mkdir(dataset_output_path + '/' + subset + '/' + categoria)\n",
    "        print('{} created'.format(dataset_output_path + '/' + subset + '/' + categoria))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad0ca96f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (2, 1), indices imply (2, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     augmented_image \u001b[38;5;241m=\u001b[39m pipeline(img \u001b[38;5;241m=\u001b[39m img)\n\u001b[1;32m     54\u001b[0m     augmented_image\u001b[38;5;241m.\u001b[39msave(new_image_path)\n\u001b[0;32m---> 56\u001b[0m new_img \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimg_name\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_tr.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphoto_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mphoto_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m dataset[subset][categoria] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([dataset[subset][categoria], new_img])\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:737\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    729\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    730\u001b[0m             arrays,\n\u001b[1;32m    731\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    734\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    735\u001b[0m         )\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 737\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    746\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    747\u001b[0m         {},\n\u001b[1;32m    748\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    751\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    752\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    347\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    348\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    349\u001b[0m )\n\u001b[0;32m--> 351\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    420\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    421\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 422\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (2, 1), indices imply (2, 2)"
     ]
    }
   ],
   "source": [
    "# copiar o generar imagenes\n",
    "\n",
    "from torchvision import transforms as T\n",
    "\n",
    "random_state = 42 # La soluci칩n de Douglas Adams para todo\n",
    "\n",
    "from torch import manual_seed\n",
    "manual_seed(random_state)\n",
    "\n",
    "import random\n",
    "random.seed(random_state)\n",
    "\n",
    "max_photos = 2500\n",
    "\n",
    "subset_max_photos = {\n",
    "    'train': int(max_photos * 0.8),\n",
    "    'test': int(max_photos * 0.1)\n",
    "}\n",
    "\n",
    "subset_max_photos.update({\n",
    "    'validate': max_photos - subset_max_photos['train'] - subset_max_photos['test'] # las que quedan\n",
    "})\n",
    "\n",
    "pipeline = T.Compose([\n",
    "    T.ColorJitter(brightness=.5, hue=.3),\n",
    "    T.RandomAffine(degrees=(30, 70), scale=(0.9, 1.1))\n",
    "])\n",
    "\n",
    "\n",
    "for subset in ['train', 'test', 'validate']:\n",
    "    for categoria in categorias:\n",
    "        # copiar\n",
    "        for img in dataset[subset][categoria].photo_id:\n",
    "            shutil.copyfile(dataset_origin_path + '/' + img + '.jpg',\n",
    "                            dataset_output_path + '/' + subset + '/' + categoria + '/' + img + '.jpg')\n",
    "        \n",
    "        # generar imagenes si necesario\n",
    "        if len(dataset[subset][categoria]) < subset_max_photos[subset]: # faltan imagenes\n",
    "\n",
    "            # determinar cuantas imagenes tendremos que generar\n",
    "            n_missing = subset_max_photos[subset] - len(dataset[subset][categoria])\n",
    "            \n",
    "            # seleccionar imagenes que vamos usar como base\n",
    "            df_base_images = dataset[subset][categoria].sample(n=n_missing,\n",
    "                                                               random_state=random_state,\n",
    "                                                               replace=False, # solo 1x cada foto\n",
    "                                                               ignore_index=True)\n",
    "            # abrir original > transformar > guardar imagen transformada > a침adir nueva foto al subset\n",
    "            for img_name in df_base_images.photo_id:\n",
    "                original_image_path = dataset_origin_path + '/' + img + '.jpg'\n",
    "                new_image_path = dataset_output_path + '/' + subset + '/' + categoria + '/' + img + '.jpg''_tr.jpg'\n",
    "                with Image.open(original_image_path) as img:\n",
    "                    augmented_image = pipeline(img = img)\n",
    "                    augmented_image.save(new_image_path)\n",
    "                \n",
    "                new_img = pd.DataFrame([img_name+'_tr.jpg', \n",
    "                                        df.loc[df.photo_id == img_name].label],\n",
    "                                       columns=['photo_id', \n",
    "                                                'label'])\n",
    "                dataset[subset][categoria] = pd.concat([dataset[subset][categoria], new_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4cdf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
